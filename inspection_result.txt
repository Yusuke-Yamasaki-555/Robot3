＜検証内容・検証結果＞
　各検証内容の下に結果(&考察)を記述。


山崎
　・プログラムから目標座標を指定して制御する方法での、座標の単位を調べる。moveit関連。
　・正確なマニピュレータの制御の方法を検証。SRDFを直接いじる(rvizを活用)か、目標物の座標を直接渡すか。
　・SRDFから直接角度を指定して動作させる方法と、プログラムから直接座標を指定して動かす方法の、それぞれの良し悪しを列挙する。
　　　結果(考察）
　　　：単位はSI系。meter
　　　：座標のとり方：x座標＝正面方向(第２関節が動ける方向)、y座標＝表面から見て左方向、ｘ座標＝上方向。右手系
　　　：
　　：座標指定(tf)
　　　：座標指定時の最大座標はほぼ寸法に同じ。寸法より少し小さく見るといい感じ。(詳細は未検証。100mm小さく見れば確実)
　　　：座標指定で入力０は無効(オイラーは有効)
　　　：quaternion_from_euler( x軸, y軸, z軸(, スカラ値) )#名前からしてクォータニオンで指定している。ここでハンドの角度をいじる。(入力値はわからん。未検証未勉強)(ライブラリ名：tf.transformations)
　　　：xyz座標値は記憶される。
　　　：オイラー角に関しては上書きではなく再定義となる。
　　　：
　　：SRDF(Moveit!)
    　：各関節の名前一覧
           crane_x7_shoulder_fixed_part_pan_joint :  z軸第一関節  deg:-170~170
           crane_x7_shoulder_revolute_part_tilt_joint  :  y軸第一関節  deg:-90~90
           crane_x7_upper_arm_revolute_part_twist_joint  :  z軸第二関節  deg:-90~90
           crane_x7_upper_arm_revolute_part_rotate_joint  :  y軸第二関節  deg:-161~2
           crane_x7_lower_arm_fixed_part_joint  :  z軸第三関節  deg:-159~87
           crane_x7_lower_arm_revolute_part_joint  :  y軸第三関節  deg:-90~90
           crane_x7_wrist_joint  :  z軸gripper回転  deg:-170~170
      ：すべての関節の値はラジアン。そのまんま与える。
    　：各関節の０°を基準に値を決める。値を上書きしてもその基準からみる。
    　：Moveit!のdocumentationを見るに、Moveit!でも目標座標を指定して自動で逆運動学を計算してくれる機能があるっぽい。
　・面、構え、礼などの各モーションに対して、自然な動きを検証。愛嬌が出るように。
　・SRDFで、ひとつだけの関節を指定して数値を送ることは可能か。
　　　：可能。group_state内で好きな関節を指定して値を送れば良い。ただ、プログラムを走らせたときにWARNがでる。
　・直前の関節の角度を維持しながら、特定の関節のみイジれるのかどうか。
　　　：可能。変えたくない関節をgroup_state内で指定しなければいい。
　・SRDFから読んだデータをプログラム内で置き換えることができるかどうか。
　　　：可能。ただSRDFを読み込んだ後に値を変更するのではなく、プログラムでモデルの関節名と値を指定して動かす流れになる。
　　　：（記述例）
　　　　　　arm.set_joint_value_target({"crane_x7_shoulder_revolute_part_tilt_joint":-0.78539816339745})
    　　　　arm.go()
　　　：（関節名定義位置）
　　　　　　~/catkin_ws/src/crane_x7_ros/crane_x7_description/urdf/crane_x7_arm.xacro
　・nodeの勉強

　・印や棒のURDFの作成及び適用。URDFの書き方から学ぶ。gazeboの方でGUIから作れるならそれで。(~中間発表までには用意)
　　　：まだ手は付けていない。
　　　：
　　　：


吉越
　・各nodeのpubとsubのやり取りを洗い出す。
 　　run.launch(実行するファイル)
    --manage.py(すべてのpythonファイルの管理を行うpyhonファイル)
        --bow.py(お辞儀)
　      --grip.py(棒を持つ)
            --cv_grip.py(棒を探す)
        --find.py(物体を探す)
            --cv_find.py
        --sprinkle.py(振りかぶる)
            以下2つの関数はsprinkle.pyに書く. 
            --not_find()(物体が見つからない)
            --not_reach()(物体に届かない)                                                                
        --hit.py(打つ)
        --check.py(すべて倒したか確認する)
            --cv_check.py
        --release.py(棒を離す)
        --gutspose.py(喜ぶ. ガッツポーズでなくてもよい.)

  ・pubとsubの関係
    manage.py: pub--OpenCV以外のファイルに指示を出す. sub--OpenCV以外のファイルの動作完了の報告を受け取る.
    OpenCV以外のファイル: pub--manage.pyに動作完了の報告をする. sub--manage.pyから動作命令を受け取り, 実行する.
    grip.py等のOpenCVと一緒に動作するファイル: pub--上の動作に加えて, OpenCVファイルへ実行命令を出す. sub--上記の動作に加えて, OpenCVファイルからデータを受け取る. 
    OpenCVファイル: pub--上のファイルにデータを送る. sub-- 上のファイルから動作命令を受け取り, 実行する.
　・openCVの、画像から抽出する色をプログラムからスムーズに変更できるか。
 　 :スムーズに変更できた. 動作させるときは一度に2色を抽出させた. これを一色づつ抽出させればよい. 
　・カメラの映す範囲を調べる。特に縦方向。
    ・レンズのある位置からおよそ上に10cm, 下に10cmの範囲を映す. (正確ではないのであくまで参考に)
　・動作を制限するためのプログラムは、時間指定が良いか行動回数指定が良いか。また適切な指定量を決める。
    ・考察の結果, 行動回数指定が良いと考えた. 理由は, プログラムでの制御が行動回数指定の方が簡単であると考えたから. 
　・必要なパッケージ(python3,ros)を洗い出す。
    ・ROS: インストール済み
    ・python3: インストール済み
    ・opencv: インストール済み
    ・moveit_commander: インストール済み
    ・geometry_msgs.msg: インストール済み
    ・rosnode: インストール済み
    ・tf: インストール済み
    ・sensor_msgs(画像などの型を渡す若しくは受ける): インストール済み
    ・cv_bridge(ros形式からOpenCV形式に変換する): インストール済み
    ・move_def(去年の5班が作ったライブラリ. 手先の位置等を簡単に設定できる. ): コピペする.
　・どのような印の形が良いか決める。ここを面白くする。

　・印や棒のURDFの作成及び適用。URDFの書き方から学ぶ。gazeboの方でGUIから作れるならそれで。(~中間発表までには用意)


追加検証
　・Moveit!で目標指定から逆運動学でアームを動かす方法の確立。



＜いいサイトまとめ＞
・Moveit!のまとめ：https://robo-marc.github.io/moveit_documents/index.html
・URDFのいいサイト：joe.ash.jp/program/ros/urdf_model/index.htm
